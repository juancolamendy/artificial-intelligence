{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"content-generation-gpt-neo.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO+O42jyvNG+ReMTrqw9XID"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7FT9dkQdCE-C"},"source":["# Install dependencies"]},{"cell_type":"code","metadata":{"id":"VgLAB7gXByHl"},"source":["!pip install --quiet transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyfAbYFHRHvs","executionInfo":{"status":"ok","timestamp":1622909484157,"user_tz":240,"elapsed":660,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}},"outputId":"484ee5c0-b2e4-4319-8475-545fd5d2bd07"},"source":["!pip list | grep transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["transformers                  4.6.1              \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QIV2Qz0oCCdC"},"source":["# Import dependencies\n"]},{"cell_type":"code","metadata":{"id":"--NzOZehCJ6V","executionInfo":{"status":"ok","timestamp":1622909494801,"user_tz":240,"elapsed":5352,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}}},"source":["from transformers import GPTNeoForCausalLM, GPT2Tokenizer"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r7KYK9cQCRUt"},"source":["# Load tokenizer and model"]},{"cell_type":"code","metadata":{"id":"3tuODT7xCTBW"},"source":["# 1.3B version\n","model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n","\n","# 2.7B version\n","# model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n","# tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywi9_BSNDotz"},"source":["!echo \"--- print out disk space\"\n","!du -sh ~/.cache/huggingface/transformers\n","!echo \"--- print out the details\"\n","!ls -alh ~/.cache/huggingface/transformers\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhJ5xDKfEFai"},"source":["!free -g"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BzLR_GxzNZwt"},"source":["## Content Generation"]},{"cell_type":"code","metadata":{"id":"tY38ABK_EZYI"},"source":["n_tokens = 40\n","prompt = \"\"\"Complete the following Paragraph given a Title and Background.\n","Title: What is philosophy?\n","Background: Philosophy is the study of general and fundamental questions.\n","Paragraph: Philosophers try to answer existential questions, they make assumptions\"\"\"\n","input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n","gen_tokens = model.generate(input_ids,\n","                            max_length= len(input_ids[0]) + n_tokens,\n","                            do_sample=True,\n","                            temperature=0.7,                           \n","                            top_k=50,\n","                            top_p=0.95,\n","                            no_repeat_ngram_size=2, )\n","gen_text = tokenizer.batch_decode(gen_tokens)[0]\n","print(\"-------\")\n","print(gen_text)"],"execution_count":null,"outputs":[]}]}