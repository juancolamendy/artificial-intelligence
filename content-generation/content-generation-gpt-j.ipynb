{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"content-generation-gpt-j.ipynb","provenance":[],"collapsed_sections":["aSHqXO03VXKP"],"authorship_tag":"ABX9TyPmRK1Nz4A+D7WL2PczveHe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2zORNKoKUc6i"},"source":["# Install dependencies"]},{"cell_type":"code","metadata":{"id":"cGkpwc42UX5W"},"source":["# !pip install einops transformers\n","!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ro3cDvKTVQld"},"source":["# Import dependencies"]},{"cell_type":"code","metadata":{"id":"Jr10W7F0VTmX","executionInfo":{"status":"ok","timestamp":1627145993324,"user_tz":240,"elapsed":12597,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}}},"source":["import os\n","import logging\n","import hashlib\n","import requests\n","from tqdm import tqdm\n","\n","from transformers import GPT2Tokenizer\n","from transformers import GPTNeoForCausalLM"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bhlXtjtdWBIi"},"source":["# Init/bootstrap"]},{"cell_type":"code","metadata":{"id":"wHOVRHMYWAVN","executionInfo":{"status":"ok","timestamp":1627144296364,"user_tz":240,"elapsed":530,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}}},"source":["# logger\n","logger = logging.getLogger(__name__)\n","logger.setLevel(logging.INFO)\n","if (logger.hasHandlers()):\n","    logger.handlers.clear()\n","\n","console = logging.StreamHandler()\n","logger.addHandler(console)\n","\n","# urls\n","urls = {\n","    'config.json': {\n","        'url': 'https://zhisu-nlp.s3.us-west-2.amazonaws.com/gpt-j-hf/config.json',\n","        'sha1sum': 'a0af27bcff3c0fa17ec9718ffb6060b8db5e54e4'\n","    },\n","    'pytorch_model.bin': {\n","        'url': 'https://zhisu-nlp.s3.us-west-2.amazonaws.com/gpt-j-hf/pytorch_model.bin',\n","        'sha1sum': 'bab870fc9b82f0bfb3f6cbf4bd6bec3f3add05a6'\n","    }\n","}"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aSHqXO03VXKP"},"source":["# Utility functions"]},{"cell_type":"code","metadata":{"id":"XJ1IkhGBVa29","executionInfo":{"status":"ok","timestamp":1627144217237,"user_tz":240,"elapsed":581,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}}},"source":["# download\n","def download(url, path=None, overwrite=False, sha1_hash=None):\n","    \"\"\"Download files from a given URL.\n","    \"\"\"\n","    if path is None:\n","        fname = os.path.join(url.split('/')[-2],url.split('/')[-1])\n","    else:\n","        path = os.path.expanduser(path)\n","        if os.path.isdir(path):\n","            fname = os.path.join(path, url.split('/')[-2], url.split('/')[-1])\n","        else:\n","            fname = path\n","\n","    if os.path.exists(fname) and sha1_hash:\n","        logger.info('File {} exist, checking content hash...'.format(fname))\n","        file_check = check_sha1(fname, sha1_hash)\n","        if file_check:\n","            logger.info('File {} checking pass'.format(fname))\n","        else:\n","            raise KeyError('File {} is downloaded but the content hash does not match. ' \\\n","                                'Please retry.'.format(fname))\n","\n","    elif overwrite or not os.path.exists(fname) :\n","        if overwrite:\n","            logger.info('File {} exist, overwriting...'.format(fname))\n","        download_ops(url,fname)\n","        if sha1_hash:\n","            logger.info('File {} downloaded, checking content hash...'.format(fname))\n","            file_check = check_sha1(fname, sha1_hash)\n","            if file_check:\n","                logger.info('File {} checking pass'.format(fname))\n","            else:\n","                raise KeyError('File {} is downloaded but the content hash does not match. ' \\\n","                                    'Please retry.'.format(fname))\n","    return fname\n","\n","# check_sha1\n","def check_sha1(filename, sha1_hash):\n","    \"\"\"Check whether the sha1 hash of the file content matches the expected hash.\n","    \"\"\"\n","    sha1 = hashlib.sha1()\n","    with open(filename, 'rb') as f:\n","        while True:\n","            data = f.read(1048576)\n","            if not data:\n","                break\n","            sha1.update(data)\n","\n","    return sha1.hexdigest() == sha1_hash\n","\n","# download_ops\n","def download_ops(url, fname):\n","    dirname = os.path.dirname(os.path.abspath(os.path.expanduser(fname)))\n","    if not os.path.exists(dirname):\n","        os.makedirs(dirname)\n","\n","    logger.info('Downloading %s from %s...'%(fname, url))\n","    r = requests.get(url, stream=True)\n","    if r.status_code != 200:\n","        raise RuntimeError(\"Failed downloading url %s\"%url)\n","    total_length = r.headers.get('content-length')\n","    with open(fname, 'wb') as f:\n","        if total_length is None: # no content length header\n","            for chunk in r.iter_content(chunk_size=1024):\n","                if chunk: # filter out keep-alive new chunks\n","                    f.write(chunk)\n","        else:\n","            total_length = int(total_length)\n","            for chunk in tqdm(r.iter_content(chunk_size=1024),\n","                                total=int(total_length / 1024. + 0.5),\n","                                unit='KB', unit_scale=False, dynamic_ncols=True):\n","                f.write(chunk)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Xw8vg9nW6yf"},"source":["# Download gptj models"]},{"cell_type":"code","metadata":{"id":"LESds6UPW9vz"},"source":["for file_name, info in urls.items():\n","  download(info['url'], './', sha1_hash=info['sha1sum'])\n","\n","logger.info(\"***download finished***\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EatRLgFTaOE1","executionInfo":{"status":"ok","timestamp":1627146010988,"user_tz":240,"elapsed":505,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}},"outputId":"ac8e2129-593d-4bba-8501-8bdc9b9083f4"},"source":["!ls -ahl gpt-j-hf"],"execution_count":6,"outputs":[{"output_type":"stream","text":["total 12G\n","drwxr-xr-x 2 root root 4.0K Jul 24 16:32 .\n","drwxr-xr-x 1 root root 4.0K Jul 24 16:32 ..\n","-rw-r--r-- 1 root root 1.4K Jul 24 16:32 config.json\n","-rw-r--r-- 1 root root  12G Jul 24 16:43 pytorch_model.bin\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HMVzIQmrasON"},"source":["# Loading model"]},{"cell_type":"code","metadata":{"id":"-0k5MrHSaulf"},"source":["model = GPTNeoForCausalLM.from_pretrained(\"./gpt-j-hf\")\n","model.eval()\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","logger.info(\"***loading finished***\")\n","\n","# This should take about 12GB of Graphics RAM, if you have a larger than 16GB gpu you don't need the half()\n","# model.half().cuda() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bQfUiLvb307"},"source":["# Predictions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"eO9mfalicj7n","executionInfo":{"status":"error","timestamp":1627145932044,"user_tz":240,"elapsed":192,"user":{"displayName":"Juan Carlos Olamendy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQ5abnImE35Fu-BNSrmYlpO4C_dqQpuG2gjJmy5Q=s64","userId":"11004855458032977781"}},"outputId":"0b95560c-cb2f-4362-db65-d2d8822110e6"},"source":["input_text = 'Why AutoGluon is great?'\n","\n","logger.info(\"***encoding***\")\n","input_ids = tokenizer.encode(str(input_text), return_tensors='pt').cuda()\n","\n","logger.info(\"***generating***\")\n","output = model.generate(\n","    input_ids,\n","    do_sample=True,\n","    max_length=args.max_length,\n","    top_p=args.top_p,\n","    top_k=0,\n","    temperature=1.0,\n",")\n","\n","output_context = tokenizer.decode(output[0], skip_special_tokens=True)\n","logger.info('***output_context: {}'.format(output_context))"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8fa4c632775e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Why AutoGluon is great?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***encoding***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"]}]}]}